# OpenCVSampleForMacOS



![image](https://upload-images.jianshu.io/upload_images/453533-756cabd51583e65c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

OpenCVæ˜¯ä¸€ä¸ªè·¨å¹³å°è®¡ç®—æœºè§†è§‰å’Œæœºå™¨å­¦ä¹ è½¯ä»¶åº“ï¼Œå¯ä»¥è¿è¡Œåœ¨Linuxã€Windowsã€Androidå’ŒMac OSæ“ä½œç³»ç»Ÿä¸Šã€‚å®ƒè½»é‡çº§è€Œä¸”é«˜æ•ˆâ€”â€”ç”±ä¸€ç³»åˆ— C å‡½æ•°å’Œå°‘é‡ C++ ç±»æ„æˆï¼ŒåŒæ—¶æä¾›äº†Pythonã€Rubyã€MATLABç­‰è¯­è¨€çš„æ¥å£ï¼Œå®ç°äº†å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰æ–¹é¢çš„å¾ˆå¤šé€šç”¨ç®—æ³•ã€‚

æœ€è¿‘ä½¿ç”¨Flutterå¼€å‘ä¸€ä¸ªOpenCVçš„APPï¼Œè°ƒè¯•æ—¶éœ€åŒæ—¶æ˜¾ç¤ºå¤šä¸ªçª—å£ï¼Œä»¥æ˜¾ç¤ºä¸åŒè¾“å‡ºç›®æ ‡ï¼Œæ‰‹æœºå±å¹•æ¯”è¾ƒå°ï¼Œæ˜¾ç¤ºå¤šä¸ªè§†å›¾æ—¶å°±æ˜¾å¾—å›°éš¾ï¼Œå³ä½¿èƒ½æ˜¾ç¤ºï¼Œä¹Ÿå› ä¸ºçª—å£å¤ªå°ï¼Œä¸å¥½åˆ†è¾¨ç›®æ ‡è¾“å‡ºå†…å®¹ã€‚äºæ˜¯æƒ³åœ¨MacOSä¸‹å…ˆè°ƒè¯•å¥½ï¼Œå†æŠŠç®—æ³•copyåˆ°iOSã€Androidä¸‹é¢ã€‚

åœ¨ç½‘ä¸Šæœç´¢äº†å¾ˆå¤šæ•™ç¨‹ï¼Œå¤§éƒ¨åˆ†å·²ç»å¹´ä»£ä¹…è¿œå·²ç»ä¸èƒ½æ­£å¸¸å®‰è£…å¥½ã€‚æˆ‘ç›®å‰ä½¿ç”¨MacOS 10.15 å®‰è£… OpenCV 4.0.1 (iOS podåº“æœ€æ–°æ˜¯4.0.1)ï¼Œé€šè¿‡Cmakeç¼–è¯‘å‡ºfarmeworkï¼Œå¯ç›´æ¥å¯¼å…¥åˆ°Macé¡¹ç›®ï¼Œä½¿ç”¨ä¸Šè¾ƒå¯¼å…¥åŠ¨æ€åº“æ–¹ä¾¿è®¸å¤šï¼Œå‡å»äº†é…ç½®Search Pathsçš„éº»çƒ¦ã€‚

#### ç¯å¢ƒé…ç½®

1.é¦–å…ˆéœ€è¦å®‰è£…Macå®‰è£…åŒ…ç®¡ç†å™¨[brew](https://brew.sh/)æˆ–[MacPorts](https://www.macports.org/) ï¼ˆå·²å®‰è£…è·³è¿‡æ­¤æ­¥éª¤ï¼‰

```
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"
```

2.å†å®‰è£…Cmakeï¼Œä½¿ç”¨å®ƒç¼–è¯‘C++

```
brew install cmake
```

or

```
port install cmake
```

3.ä¸‹è½½opencv.zip
ä½¿ç”¨æµè§ˆå™¨åˆ°OpenCV GitHubä¸‹è½½é¡µé¢[https://github.com/opencv/opencv/releases](https://github.com/opencv/opencv/releases)ä¸‹è½½ä½ éœ€è¦ä½¿ç”¨çš„OpenCVç‰ˆæœ¬ï¼Œæˆ‘ç›®å‰ä½¿ç”¨çš„æ˜¯[4.0.1](https://codeload.github.com/opencv/opencv/zip/4.0.1)

#### ç¼–è¯‘framework

1ã€è§£å‹OpenCV.zip
2ã€ä½¿ç”¨ç»ˆç«¯cdåˆ°OpenCVè§£å‹ç›®å½•(e.g.)

```
cd ~/Desktop/opencv-4.0.1/
```

3ã€ä½¿ç”¨Pythonè„šæœ¬ç¼–è¯‘opencv2.framework

```
python platforms/osx/build_framework.py frameworks
```

æˆ‘çš„Macç¼–è¯‘æ—¶å‡ºç°æŠ¥é”™ï¼Œæˆ‘æŠŠbuild_framework.pyä¸­çš„MACOSX_DEPLOYMENT_TARGETæ”¹ä¸º10.13å°±ç¼–è¯‘æˆåŠŸäº†ï¼æœ‰å¯èƒ½æ˜¯é»˜è®¤çš„10.9ä¼šå¤„ç†æœ‰å…³32ä½çš„é—®é¢˜ã€‚
build_framework.pyä½äºè§£å‹æ–‡ä»¶ç›®å½•çš„platforms/osx/ä¸‹
ä¿®æ”¹åæ–‡ä»¶å¦‚ä¸‹ï¼š

```
#!/usr/bin/env python
"""
The script builds OpenCV.framework for OSX.
"""

from __future__ import print_function
import os, os.path, sys, argparse, traceback, multiprocessing

# import common code
sys.path.insert(0, os.path.abspath(os.path.abspath(os.path.dirname(__file__))+'/../ios'))
from build_framework import Builder

class OSXBuilder(Builder):

    def getToolchain(self, arch, target):
        return None

    def getBuildCommand(self, archs, target):
        buildcmd = [
            "xcodebuild",
            "MACOSX_DEPLOYMENT_TARGET=10.13",
            "ARCHS=%s" % archs[0],
            "-sdk", target.lower(),
            "-configuration", "Release",
            "-parallelizeTargets",
            "-jobs", str(multiprocessing.cpu_count())
        ]
        return buildcmd

    def getInfoPlist(self, builddirs):
        return os.path.join(builddirs[0], "osx", "Info.plist")


if __name__ == "__main__":
    folder = os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "../.."))
    parser = argparse.ArgumentParser(description='The script builds OpenCV.framework for OSX.')
    parser.add_argument('out', metavar='OUTDIR', help='folder to put built framework')
    parser.add_argument('--opencv', metavar='DIR', default=folder, help='folder with opencv repository (default is "../.." relative to script location)')
    parser.add_argument('--contrib', metavar='DIR', default=None, help='folder with opencv_contrib repository (default is "None" - build only main framework)')
    parser.add_argument('--without', metavar='MODULE', default=[], action='append', help='OpenCV modules to exclude from the framework')
    parser.add_argument('--enable_nonfree', default=False, dest='enablenonfree', action='store_true', help='enable non-free modules (disabled by default)')
    args = parser.parse_args()

    b = OSXBuilder(args.opencv, args.contrib, False, False, args.without, args.enablenonfree,
        [
            (["x86_64"], "MacOSX")
        ])
    b.build(args.out)
```

#### åˆ›å»ºMacé¡¹ç›®ï¼Œå¯¼å…¥OpenCV

æ‰“å¼€Xcode->File -> New Projectï¼Œé€‰æ‹©APPã€‚

![image](https://upload-images.jianshu.io/upload_images/453533-5c08bf2393282e0f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
è¾“å…¥é¡¹ç›®åç§°OpenCVSampleï¼ŒLanguageé€‰æ‹©Swift,User Innterfaceé€‰æ‹©XIB

![image](https://upload-images.jianshu.io/upload_images/453533-05b51022c62ba700.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

åœ¨APPdelegateä¸­é…ç½®windowå’ŒcontentViewControllerã€‚
APPdelegate.swift

```
    var mainWindowController: NSWindowController!

    lazy var window: NSWindow = {
        let w = NSWindow(contentRect: NSMakeRect(0, 0, 1007 , 641), styleMask: [.titled, .resizable, .miniaturizable, .closable, .fullSizeContentView], backing: .buffered, defer: false)
        w.center()
        w.backgroundColor = NSColor(calibratedRed: 0, green: 0, blue: 0, alpha: 1)
        w.minSize = NSMakeSize(320, 240)

        return w
    }()

    func applicationDidFinishLaunching(_ aNotification: Notification) {
        // Insert code here to initialize your application
        mainWindowController = NSWindowController(window: window)
        mainWindowController.showWindow(nil)
        mainWindowController.window?.makeKeyAndOrderFront(nil)

        NSApplication.shared.mainWindow?.title = "OpenCV Sample"
        let scanViewCtrl = ScanViewController()
        window.contentViewController = scanViewCtrl
    }
```

å°†MainMenu.xibä¸­çš„é»˜è®¤windowåˆ é™¤ï¼Œåˆ é™¤åå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
![image](https://upload-images.jianshu.io/upload_images/453533-a031b1e13d9beed6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

#### æµ‹è¯•OpenCV

åˆ›å»ºopencvè§†é¢‘å¤„ç†æ¡¥æ¥æ–‡ä»¶
CVCamera.h

```
@interface CVCamera : NSObject

- (id) initWithController: (NSViewController<CVCameraDelegate>*)c andCameraImageView: (NSImageView*)iv processImage: (NSImageView *)processIv;
- (void)start;
- (void)stop;

@end
```

CVCamera.mm

```
#import <opencv2/opencv.hpp>
#include "CVCamera.h"

using namespace cv;
using namespace std;

@interface CVCamera ()

@end

@implementation CVCamera
{
    NSViewController<CVCameraDelegate> * delegate;
    NSImageView * cameraimageView;
    NSImageView * processimageView;
    VideoCapture cap;
    cv::Mat gtpl;
    int cameraIndex;
    NSTimer *timer;
}

- (id) initWithController: (NSViewController<CVCameraDelegate>*)c andCameraImageView: (NSImageView*)iv processImage:(NSImageView *)processIv
{
    delegate = c;
    cameraimageView = iv;
    processimageView = processIv;

    cameraIndex = -1;
    timer = [NSTimer timerWithTimeInterval:30/1000.0 target:self selector:@selector(show_camera) userInfo:nil repeats:true];
    [[NSRunLoop mainRunLoop] addTimer:timer forMode:NSRunLoopCommonModes];
    return self;
}

- (void)processImage:(cv::Mat &)img {
    cv::Mat gimg;

    // Convert incoming img to greyscale to match template
    cv::cvtColor(img, gimg, COLOR_BGR2GRAY);

    // 5*5æ»¤æ³¢
    cv::Mat blurred;
    cv::blur(gimg, blurred, cv::Size(5, 5));

    imshow("blurred", blurred);

    // è‡ªé€‚åº”äºŒå€¼åŒ–æ–¹æ³•
    cv::Mat adaptiveThreshold;
    cv::adaptiveThreshold(blurred, adaptiveThreshold, 255, cv::ADAPTIVE_THRESH_MEAN_C, cv::THRESH_BINARY, 15, 5);
    // cannyè¾¹ç¼˜æ£€æµ‹
    cv::Mat edges;
    cv::Canny(adaptiveThreshold, edges, 10, 100);
    // ä»è¾¹ç¼˜å›¾ä¸­å¯»æ‰¾è½®å»“
    std::vector<std::vector<cv::Point>> contours;
    findContours(edges, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_SIMPLE);

    double maxArea = 0;

    vector<cv::Point> approx;
    vector<cv::Point> docCnt;
    vector<cv::Point> maxAreaContour;
    for (size_t i = 0; i < contours.size(); i++)
    {
        double area = contourArea(contours[i]);
        if (area > maxArea) {
            maxArea = area;
            maxAreaContour = contours[i];
        }
    }

    // approximate contour with accuracy proportional
    // to the contour perimeter
    approxPolyDP(maxAreaContour, approx, arcLength(maxAreaContour, true)*0.02, true);

    // Note: absolute value of an area is used because
    // area may be positive or negative - in accordance with the
    // contour orientation
    if (approx.size() == 4 &&
            isContourConvex(Mat(approx)))
    {
        docCnt = approx;
        std::vector<std::vector<cv::Point>> showContours(1);
        showContours[0] = docCnt;
        drawContours(img, showContours, -1, Scalar(208, 19, 29), 2);
    }
}

- (void)start
{
    [self openCamera];
}

- (void)stop
{
//    videoCap.close();
}

- (void)openCamera {
    VideoCapture capture = VideoCapture(0);
    if (capture.isOpened()) {
        self->cap = capture;
        self->cameraIndex = 0;
    } else {
        VideoCapture capture_usb = VideoCapture(1);
        if (capture_usb.isOpened()) {
            self->cap = capture_usb;
            self->cameraIndex = 1;
        } else {
            printf("æœªæ‰¾åˆ°æ‘„åƒå¤´,è¯·æ£€æŸ¥è®¾å¤‡è¿æ¥");
            return;
        }
    }

    self->cap.set(3, 1400);
    self->cap.set(4, 1050);

    [self->timer setFireDate:[NSDate distantPast]];
;

}

- (void)show_camera {
    if (self->cap.isOpened()) {
        Mat frame;
        self->cap.read(frame);
        NSImage *image = MatToNSImage(frame);
        self->cameraimageView.image = image;

        // processImage
        Mat processFrame = frame.clone();
        [self processImage:processFrame];
        NSImage *processimage = MatToNSImage(processFrame);
        self->processimageView.image = processimage;
    }
//    if (self.recongnitioned) {
//        self.recognition()
//    }
}

/// Converts an NSImage to Mat.
static void NSImageToMat(NSImage *image, cv::Mat &mat) {

    // Create a pixel buffer.
    NSBitmapImageRep *bitmapImageRep = [NSBitmapImageRep imageRepWithData:image.TIFFRepresentation];
    NSInteger width = bitmapImageRep.pixelsWide;
    NSInteger height = bitmapImageRep.pixelsHigh;
    CGImageRef imageRef = bitmapImageRep.CGImage;
    cv::Mat mat8uc4 = cv::Mat((int)height, (int)width, CV_8UC4);
    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
    CGContextRef contextRef = CGBitmapContextCreate(mat8uc4.data, mat8uc4.cols, mat8uc4.rows, 8, mat8uc4.step, colorSpace, kCGImageAlphaPremultipliedLast | kCGBitmapByteOrderDefault);
    CGContextDrawImage(contextRef, CGRectMake(0, 0, width, height), imageRef);
    CGContextRelease(contextRef);
    CGColorSpaceRelease(colorSpace);

    // Draw all pixels to the buffer.
    cv::Mat mat8uc3 = cv::Mat((int)width, (int)height, CV_8UC3);
    cv::cvtColor(mat8uc4, mat8uc3, cv::COLOR_RGBA2BGR);

    mat = mat8uc3;
}

/// Converts a Mat to NSImage.
static NSImage *MatToNSImage(cv::Mat &mat) {

    // Create a pixel buffer.
    assert(mat.elemSize() == 1 || mat.elemSize() == 3);
    cv::Mat matrgb;
    if (mat.elemSize() == 1) {
        cv::cvtColor(mat, matrgb, cv::COLOR_GRAY2RGB);
    } else if (mat.elemSize() == 3) {
        cv::cvtColor(mat, matrgb, cv::COLOR_BGR2RGB);
    }

    // Change a image format.
    NSData *data = [NSData dataWithBytes:matrgb.data length:(matrgb.elemSize() * matrgb.total())];
    CGColorSpaceRef colorSpace;
    if (matrgb.elemSize() == 1) {
        colorSpace = CGColorSpaceCreateDeviceGray();
    } else {
        colorSpace = CGColorSpaceCreateDeviceRGB();
    }
    CGDataProviderRef provider = CGDataProviderCreateWithCFData((__bridge CFDataRef)data);
    CGImageRef imageRef = CGImageCreate(matrgb.cols, matrgb.rows, 8, 8 * matrgb.elemSize(), matrgb.step.p[0], colorSpace, kCGImageAlphaNone|kCGBitmapByteOrderDefault, provider, NULL, false, kCGRenderingIntentDefault);
    NSBitmapImageRep *bitmapImageRep = [[NSBitmapImageRep alloc] initWithCGImage:imageRef];
    NSImage *image = [NSImage new];
    [image addRepresentation:bitmapImageRep];
    CGImageRelease(imageRef);
    CGDataProviderRelease(provider);
    CGColorSpaceRelease(colorSpace);

    return image;
}

+ (NSImage *)cvtColorBGR2GRAY:(NSImage *)image {
    cv::Mat bgrMat;
    NSImageToMat(image, bgrMat);
    cv::Mat grayMat;
    cv::cvtColor(bgrMat, grayMat, cv::COLOR_BGR2GRAY);
    NSImage *grayImage = MatToNSImage(grayMat);
    return grayImage;
}

@end
```

é¡¹ç›®ä¸­ä½¿ç”¨swiftè¯­è¨€å¼€å‘ï¼Œéœ€è¦åˆ›å»ºæ¡¥æ¥æ–‡ä»¶OpenCVSampleForMacOS-Bridging-Header.hï¼Œå¹¶ä¸”åœ¨é…ç½®ä¸­è®¾ç½®æ¡¥æ¥æ–‡ä»¶ã€‚

OpenCVSampleForMacOS-Bridging-Header.h

```
#ifndef OpenCVSampleForMacOS_Bridging_Header_h
#define OpenCVSampleForMacOS_Bridging_Header_h

#import "CVCamera.h"

#endif /* OpenCVSampleForMacOS_Bridging_Header_h */
```

åˆ›å»ºä¸€ä¸ªå±•ç¤ºè§†é¢‘å†…å®¹çš„ScanViewControllerï¼š

```
import Foundation

class ScanViewController: NSViewController, CVCameraDelegate {

    lazy var previewImageView: NSImageView = {
        let imgView = NSImageView(frame: NSRect(x: 10, y: 10, width: 480, height: 320))

        return imgView
    }()

    lazy var processImageView: NSImageView = {
        let imgView = NSImageView(frame: NSRect(x: 520, y: 10, width: 480, height: 320))

        return imgView
    }()

    lazy var label: NSTextField = {
        let v = NSTextField(labelWithString: "Press the button")
        v.translatesAutoresizingMaskIntoConstraints = false

        return v
    }()


    lazy var button: NSButton = {
        let v = NSButton(frame: .zero)
        v.translatesAutoresizingMaskIntoConstraints = false

        return v
    }()

    var camera: CVCamera!

    override func loadView() {
        // è®¾ç½® ViewController å¤§å°åŒ mainWindow
        guard let windowRect = NSApplication.shared.windows.first?.frame else { return }
        view = NSView(frame: windowRect)
    }

    override func viewDidLoad() {
        super.viewDidLoad()
        view.addSubview(label)
        view.addSubview(button)
        view.addSubview(previewImageView)
        view.addSubview(processImageView)

        camera = CVCamera(controller: self, andCameraImageView: previewImageView, processImage:processImageView);

        NSLayoutConstraint.activate([
            label.centerXAnchor.constraint(equalTo: view.centerXAnchor),
            label.centerYAnchor.constraint(equalTo: view.centerYAnchor, constant: -20),

            button.centerXAnchor.constraint(equalTo: view.centerXAnchor),
            button.topAnchor.constraint(equalTo: label.bottomAnchor, constant: 20),
            button.heightAnchor.constraint(equalToConstant: 30),
            button.widthAnchor.constraint(equalToConstant: 100)
            ])

        button.title = "å¼€å§‹"
        button.target = self
        button.action = #selector(onClickme)
    }

    func matchedItem() {

    }

    @objc func onClickme(_ sender: NSButton) {
        label.textColor = .red
        label.stringValue = "ğŸ‘Œ!"

        camera.start()
    }
}
```

#### ç»“æœ

Command+R è¿è¡Œç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š
é€šè¿‡openCVè¯†åˆ«å‡ºæœ€å¤§è¾¹æ¡†å¹¶ä¸”è¿›è¡Œæ˜¾ç¤ºã€‚
![image](https://upload-images.jianshu.io/upload_images/453533-38226a02f2596877.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

#### å‚è€ƒ

- https://github.com/ura14h/OpenCVSample
- https://blog.devtang.com/2012/10/27/use-opencv-in-ios/
